%preamble.tex
= Lecture 14: Continuous-time Markov chains=
= Outline=
== Outline ==
* Continuous-time Markov chains.
    * transition rate matrix
    * steady-state distribution
    * Poisson process



= Discrete time review =


== Markov chains ==
* Let $x_t$ take one of $N$ discrete values: $\{S_1,...,S_N\}$.
* We denote the probability that $x_t=S_n$ by $\pi_{nt}$.
* The row vector of probabilities is $\pi_t=\{\pi_{1t},...,\pi_{Nt}\}$.
* The probability of moving from state $i$ to state $j$ is $P_{ij}$.
* These probabilities can be collected in a \emph{transition matrix} $P$.
\[
\pi_{t+1} = \pi_t P
\]


== Forecasting with Markov chains ==
* If the system starts from state $\pi_0$, the probability distribution of the states at time $t$:
\[
\pi_{t} = \pi_{t-1} P = \pi_{t-2} P^2=...= \pi_0 P^t
\]
* We can use this iteration to forecast any future state of the system.



== Stationary distribution ==
* The stationary (invariant) distribution is such that
\[
\pi^* = \pi^* P.
\]
* This is the eigenvector corresponding to the eigenvalue 1.
\[
0 = \pi^* (I-P).
\]


== Stationary distribution ==
* Because $P$ is stochastic, there is always at least one eigenvalue of 1.
* $\pi^*$ is unique if 1 is not a multiple eigenvalue.
* $\pi^*$ is asymptotic stationary if all other eigenvalues are less than 1 in absolute value.

== Example ==
* Take the following $2\times2$ transition matrix:
\[
P = \begin{bmatrix}
            0.9 & 0.1 \\
            0.3 & 0.7 \\
          \end{bmatrix}
\]
* The steady-state distribution is
\[
\pi^* = \begin{pmatrix}
            0.75 \\
            0.25 \\
          \end{pmatrix}
\]



= Continuous time =
== Moving to continuous time ==
* Let us now take $\Delta $ to 0.
* The set of possible states is fixed, $S_1,...,S_N$.
* What changes with $\Delta $ is the transition matrix: $P(\Delta )$.

== Moving to continuous time ==
* Intuitively, we don't expect any change over a very short $\Delta \approx 0$ period of time:
\[
\lim_{\Delta \to0} P(\Delta ) = I.
\]
* But over any positive amount of time, the transition matrix should be nontrivial
\[
P(\Delta ) \neq I \text{ for all }\Delta >0.
\]
* As $\Delta \to0$, we should put more and more weight on the diagonal elements of $P$ (the probability of no change).
* How to describe such a Markov process?
  * Formally, we want $P(\Delta )-I$ to be $O(\Delta )$.

== A rescaled transition matrix ==
* The probability of staying in state $i$:
\[
P_{ii}(\Delta ) = 1-\Lambda_i\Delta .
\]
* The probability of jumping to state $j$:
\[
P_{ij}(\Delta ) = \lambda_{ij}\Delta .
\]
* (In fact, any function of order $O(\Delta )$ will do.)
\[
P_{ii}(\Delta ) = \exp\left(-\Lambda_i\Delta \right).
\]
\[
P_{ij}(\Delta ) = 1 - \exp\left(-\lambda_{ij}\Delta \right).
\]


== Transitions ==
* So that $P(\Delta )$ is a transition matrix, we need
\[
\Lambda_i = \sum_{j\neq i}\lambda_{ij}
\]
* The $\lambda_{ij}$s fully characterize the dynamics of this system.
* These can be called arrival rates, hazard rates, birth rates if $j=i+1$, death rates if $j=i-1$.
* Note that $\lambda_{ij}$ is an arrival ''rate'', not a probability.
  * It can take any non-negative value, not just $[0,1]$.

== The transition ``rate" matrix ==
* More generally, we know that $P(\Delta)-I$ is $O(\Delta)$.
* This means that
\[
\lim_{\Delta\to0}\frac{P(\Delta)-I}{\Delta} \equiv \Lambda
\]
exists.
    * Because $P(\Delta)\mathbf 1=\mathbf 1$ ($P$ is stochastic), $\Lambda\mathbf 1=\mathbf 0$.
    * The diagonal elements are negative,
    * the off-diagonals are positive.
* We call the matrix $\Lambda$ the ''transition rate matrix''.
    * In more formal math, $\Lambda$ is called the ''generator matrix'' or the $Q$-matrix.
    * Together with an initial distribution, $\pi_0$, this fully characterizes the continuous-time Markov chain.


== Example 1: Employment and unemployment ==
* The hazard rate of losing a job is $\delta$.
  * The lifetime of a job is exponential with mean $1/\delta$.
  * Job loss is memoryless: you are just as likely to get fired on your 2nd day as on your 366th.
* The arrival rate of a new job for an unemployed is $\lambda$.
  * The spell of unemployment is exponential with mean $1/\lambda$.
  * Unemployment is memoryless: you are just as likely to find a job after 1 day of unemployment as after 365.

== Example 1: continued ==
* State 0: employment.
* State 1: unemployment.
\[
\Lambda = \begin{bmatrix}
            -\delta & \delta \\
            \lambda & -\lambda \\
          \end{bmatrix}
\]

== Example 2: incoming emails ==
* Let $n(t)$ be the number of emails in your inbox at time $t$.
* We want to characterize the dynamics of $n$.
* Suppose emails arrive at random (think of spam).
  * You never erase email:
  \[
  \lambda_{i,j}=0\text{ if }j<i
  \]
  * No two emails arrive at the same time:
  \[
  \lambda_{i,i+s}=0\text{ for all }s\ge 2
  \]
  * Each new email arrives with a constant arrival rate:
  \[
  \lambda_{i,i+1}=\lambda
  \]
  * By construction, $\Lambda_i=\lambda$.
* This is called a Poisson process.

== Example 2 (continued) ==
The transition rate matrix for the Poisson process:
\[
\begin{bmatrix}
  -\lambda  & \lambda   & 0         & \cdots \\
  0         & -\lambda  & \lambda   & \cdots \\
  0         & 0         & -\lambda  & \cdots \\
  \vdots    & \vdots    & \vdots    & \ddots \\
\end{bmatrix}
\]






= Forecasting with Markov chains =
== Example 1: Employment and unemployment ==
* Suppose you start out employed at $t=0$, $\pi_0(0)=1$.
* What is the probability that you will be employed at $t+\Delta$?
\[
\pi_0(t+\Delta) = (1-\delta\Delta)\pi_0(t) + \lambda\Delta \pi_1(t)
\]
    * with prob $(1-\delta\Delta)$ you remained in state 0
    * with prob $\lambda\Delta$ you exited from state 1

== Example 1: Employment and unemployment ==
\[
\pi_0(t+\Delta) = (1-\delta\Delta)\pi_0(t) + \lambda\Delta \pi_1(t)
\]
* Subtract $\pi_0(t)$ from both sides and divide by $\Delta$.
\[
\frac{\pi_0(t+\Delta)-\pi_0(t)}{\Delta} = -\delta \pi_0(t) + \lambda \pi_1(t) =
-\delta \pi_0(t) + \lambda [1-\pi_0(t)]
\]
* Take $\Delta\to0$
\[
\dot\pi_0(t) = \lambda-(\lambda+\delta) \pi_0(t)
\]
* This is a first-order ordinary differential equation, known as the Kolmogorov forward equation.


== The Kolmogorov equation ==
\[
\dot\pi_0(t) = \lambda-(\lambda+\delta) \pi_0(t)
\]
* To get the likelihood of each state at any $t$, we can solve the Kolmogorov equation forward, starting from an initial value at $t=0$.
* The solution to this ODE
\[
\pi_0(t) = \frac{\lambda}{\lambda+\delta}\left[1-Ce^{-(\lambda+\delta)t}\right],
\]
where $C$ is a constant of integration (pinned down by the boundary condition).

== The steady-state distribution ==
* The steady-state distribution of employment is
\[
\lim_{t\to\infty}\pi_0(t) = \frac{\lambda}{\lambda+\delta}.
\]
* (We will also derive with another method.)

== More generally ==
* More generally, the Kolmogorov equation is
\[
\dot \pi(t) = \pi(t) \Lambda.
\]
* Given an initial $\pi(0)$ and a transition rate matrix $\Lambda$, we can calculate the probability of each state in any future $t$.
    * Often there is no analytical solution for this ODE.
    * However, in dynamic programming it is sufficient to only look at the ''immediate future''.
    * The transition rates will be sufficient to do recursive optimization.

== The limit argument ==
* Discrete-time Markov chain
\[
\pi_{t+\Delta} = \pi_t P(\Delta)
\]
* Rate of change
\[
\frac{\pi_{t+\Delta}-\pi_t}{\Delta} = \pi_t \frac{P(\Delta)-I}{\Delta}
\]
* Take $\Delta\to0$:
\[
\dot\pi_{t}= \pi_t \Lambda
\]


== The stationary distribution ==
* A stationary distribution $\pi^*$ satisfies $\dot\pi=0$, so
\[
\pi^* \Lambda = 0.
\]

== Example 1: Employment and unemployment ==
* Remember the transition rate matrix:
\[
\Lambda = \begin{bmatrix}
            -\delta & \delta \\
            \lambda & -\lambda \\
          \end{bmatrix}
\]
* We are looking for $\pi_0^*$ and $\pi_1^*=1-\pi_0^*$ such that $\pi^* \Lambda = 0$.
* That is,
\[
-\delta \pi_0^* +\lambda (1-\pi_0^*)=0.
\]


== Example 1: Employment and unemployment ==
\[
-\delta \pi_0^* +\lambda (1-\pi_0^*)=0.
\]
* This gives us
\[
\pi_0^* = \frac{\lambda}{\lambda+\delta}.
\]
* The same as $\pi_0(\infty)$ (not a coincidence).
...
* The steady-state probability of employment
    * increases in the job finding rate
    * decreases in the firing rate


== Example 3: A faulty email server ==
* New emails arrive with rate $\lambda$:
    * $n\to n+1$
* With arrival rate $\eta$, all emails are lost
    * $n\to 0$

== Example 4: The CEU email server ==
* New emails arrive with rate $\lambda$:
    * $n\to n+1$
* After $n$ reaches $N$, all emails are lost ''immediately''
...
* What does ''immediately'' mean in this setup?
    1. $N\to0$ with arrival rate $\eta$, where $\eta\to\infty$
    2. $N$ is never reached from $N-1$

= Questions =
== Questions ==
Take the 3 different email servers and
1. Write down the transition rate matrix.
2. Write down the Kolmogorov forward equation.
3. Solve for the steady-state distribution.


== Example 3: A faulty email server ==
* The transition rate matrix:
\begin{bmatrix}
  -\lambda  & \lambda       & 0             & \cdots \\
  \eta      & -\lambda-\eta & \lambda       & \cdots \\
  \eta      & 0             & -\lambda-\eta & \cdots \\
  \vdots    & \vdots        & \vdots        & \ddots \\
\end{bmatrix}

== Example 3: A faulty email server ==
* What is the stationary distribution of this process?
* For all $n\ge0$:
\[
\lambda \pi_n^* -(\lambda+\eta)\pi_{n+1}^* = 0
\]
* This defines $\pi_{n+1}^*$ recursively as
\[
\pi_{n+1}^* = \frac{\lambda}{\lambda+\eta}\pi_{n}^*.
\]
(A geometric distribution.)
* In turn,
\[
\pi_{0}^* = \frac{\eta}{\lambda+\eta}.
\]
(To make sure that $\pi_{n}^*$s sum to 1.)

==  ==
\widefigure{geometric}{A geometric distribution}

= The Poisson process =
== The Poisson process ==
* The possible states are $n=0,1,2,....$.
* The Poisson process is characterized by an ''arrival rate'' $\lambda$ (aka hazard rate).
* The transition rate matrix is
\[
\begin{bmatrix}
  -\lambda  & \lambda   & 0         & \cdots \\
  0         & -\lambda  & \lambda   & \cdots \\
  0         & 0         & -\lambda  & \cdots \\
  \vdots    & \vdots    & \vdots    & \ddots \\
\end{bmatrix}
\]
...
* The Poisson process is used to characterize ''rare, memoryless'' events.

== Examples ==
* Phone calls to emergency center.
* Particles emitted via radioactive decay.
* Views of the CEU website.

== Characterizing the Poisson process ==
The two key characteristics of the Poisson process
    1. No two events happen at the same time (``rare events").
    2. The future arrival of events is independent of past events (``memoryless").

== Characterizing the Poisson process ==
The Poisson process may arise
* from a truly memoryless process
    * radioactive decay
* from the law of small numbers
    * view of the CEU website from California

== ==
\widefigure{ceuvisitsfromca}{Visits to econ.ceu.hu from California}
\widefigure{shirts}{Export shipments of shirts from the U.S.}
\widefigure{shirts2iceland}{Export shipments of shirts from the U.S. to Iceland}

== Counterexamples ==
* Emergency phone calls during a natural disaster.
* Arrival of guests at a restaurant.
* Your phone calls to your mother.


== Properties of the Poisson process ==
* The waiting time between the $n-1$sth and $n$th arrival is $T_n$.
* $T_n$ is random, exponentially distributed with parameter $\lambda$:
\[
\Pr(T_n \le t) = 1-\exp(-\lambda t).
\]
* Waiting times are independent.

== Properties of the Poisson process ==
* Let $N=n(t+h)-n(t)$ denote the number of arrivals between $t$ and $t+h$.
* $N$ is a Poisson-distributed random variable with parameter $\lambda h$.
* It takes on values $0,1,2,...$ with pdf
\[
\Pr(n=k) = \frac{\exp(-\lambda h)(\lambda h)^k}{k!}
\]

== Properties of Poisson processes (continued) ==
* Take two independent Poisson processes with arrival $\lambda_1$ and $\lambda_2$.
  * The sum is also a Poisson process with arrival $\lambda_1+\lambda_2$.
  * The waiting time for the first arrival is exponential with parameter $\lambda_1+\lambda_2$.
...
* Take a Poisson processes with arrival $\lambda$ and a probability $p$.
* Kill each arrival with probability $1-p$.
    * The new process is Poisson with arrival $p\lambda$.

== Notation ==
* Let $J(t)$ denote the number of arrivals of a standard Poisson process between time $0$ and time $t$.
* For any $t$, $J(t) \sim \text{Poisson(t)}$.
* Notation for a jump process of arrival $\lambda$ and jumps of size $x$:
\[
x J(\lambda t)
\]
* Graph.

== Poisson representation of Markov chains ==
* Think of a Markov chain with $N$ states.
* Starting in any given state, only $N-1$ things can happen (or nothing).
* Each $N-1$ jump has its own arrival rate.
* The first jump occurs with a Poisson arrival $\lambda_1+...+\lambda_{n-1}$ (see above).

== Poisson representation of Markov chains (continued) ==
* Once there ''is'' a jump, which one is it?
* It could be any one of the $1,...,n-1$.
* The probability of jump 1 is
\[
\frac{\lambda_1}{\lambda_1+...+\lambda_{n-1}}.
\]
...
* This is a good old probability $\in[0,1]$.
* This looks more like a discrete transition matrix.
...
* I find it useful to think about Markov chains as the sum of Poisson processes.

== Checklist ==
By now you should understand
1. continuous-time Markov chain
2. arrival rate matrix
3. forward Kolmogorov equation
4. stationary distribution
5. Poisson process
6. Poisson distribution
