% ./preamble.tex
= Lecture 13: Continuous time dynamics=
== Learning outcomes ==
You will have applicable knowledge of
    * discrete-state Markov processes in continuous time
    * dynamic programming in continuous time
        * without uncertainty
        * with discrete-state uncertainty
    * using dynamic programming in general equilibrium
    * aggregation of heterogeneous agent models

== Applications ==
We will cover three applications:
 1. The expanding variety model of growth (Grossman and Helpman)
 2. The rising product quality model of growth (Aghion and Howitt)
 3. A firm-level model of innovation (Klette and Kortum)

= Outline=
== Outline ==
* Today we review Markov processes.
* We show how they work in continuous time.
* We consider two cases:
  * no uncertainty
  * discrete states

== What we don't do ==
* Hamiltonians and calculus of variations
...
    * Hamiltonians are an engineer's way of thinking.
    * The recursive formulation is much more intuitive from the point-of-view of a decision maker in an ever-changing environment.
...
* Wiener processes and Brownian motions
...
    * They are very useful in finance.
    * but they require a special set of tools.




= Why continuous time? =
== Why continuous time? ==
* Time ''is'' continuous, only measurement is discrete.
    * Q1 GDP measures all the value added in the economy between January 1, 2009, 12am and March 31, 2009, 11.59.59pm.
    * Prices are measured monthly, unemployment is reported weekly.
    * Full-population census is usually done every 10 years.
...
* It is often useful to think about the "true" model first and then ask how it is measured.
...
* Often, continuous-time math is simpler.

== Continuous time ==
* In continuous time, $t\in \mathbb R$.
* There are no special points or intervals, all $t$ are similar.
  * We can define arbitrary intervals as we wish.
* Continuous time forces you to think about flows and stocks carefully.

== Example 1: "Bill Gates could buy Costa Rica" ==
* ''Forbes'' reports that Bill Gates' net worth, \$50 billion, is higher than the GDP of Costa Rica, hence "Bill Gates could buy Costa Rica".
* We, economists, know this is totally stupid: net worth is a ''stock'', GDP is a ''flow''.
* But just in case:
    * In continuous time, the two actually have different units: GDP is measured in \$/year (or second), net worth is measured in \$.
    * They cannot be added, subtracted or compared.
    * Even the math does not let you commit this silly mistake.

== Example 2: Cash-in-advance models ==
* In cash-in-advance models, all your period consumption has to be financed by your cash in hand:
\[
C_t \le M_t.
\]
...
* But $C_t$ is a flow, $M_t$ is a stock!
* This comparison does not make sense until you know how often you can replenish your stock of $M$.
\[
C(t,t+\Delta)\equiv \int_t^{t+\Delta}c(s)ds \le M(t)
\]
* The choice of time period, $\Delta$, is crucial.

== Example 2 (continued) ==
* In practice, there are very few actual flows (maybe your electricity consumption).
* Income, production, consumption etc mostly happen in chunks (you rarely buy a new computer).
* We will also learn tools to deal with these rare occurrences.

== When to use continuous-time modelling? ==
* Use continuous time if
  * you need simple and clean formulas
  * you want to think about your problem at different intervals
...
* Use discrete time instead if
  * you want to simulate your model in a computer (for a computer, nothing is continuous)
  * you want to estimate your model on data measured at discrete intervals (years, quarters, months)
  * your model assigns a special role to certain points or intervals in time (e.g. trading day).




= Markov processes =
== Markov processes ==
* A Markov process is a stochastic process for which
    conditional on the present state of the system, its past and future are independent.
* Time homogeneous Markov processes:
\[
\mathrm{Pr}\big[X(t+h) = y \mid X(t) = x\big] = \mathrm{Pr}\big[X(h) = y \mid X(0) = x\big]
\]
* Many processes have a Markovian representation.

== Example: An AR(1) process  ==
* Suppose GDP follows an AR(1) process:
\[
y_t = \rho y_{t-1} + u_t
\]
* Knowing $y_{t}$ helps you predict $y_{t+1}$, $y_{t+2}$, etc.
...
* But the key is that ''nothing else does''.

== Markovian representations ==
* What if the future depends on the past, not only the present?
    * Say, unemployment next week depends on last week's number, but also on seasonality.
    * We can always increase the state space to include last year's number.
...
* What if there are "news" about the future that are informative?
    * Say, technological developments are reported in Science and this affects future GDP growth.
    * Again, we can include a state variable (or vector) to account for these news.
    * This works as long the news themselves have Markovian dynamics.
...
* One can use Markovian tools for even inherently forward-looking phenomena.
    * Say, the continuation value in a dynamic contract can be a state variable. (Sargent calls this "dynamic programming squared".)



= No uncertainty =
= Discrete time review =
== First-order difference equations ==
* Let $x_t$ be a $k\times1$ vector.
* $x_t$ follows a first-order difference equation if $\Delta x_t\equiv x_t-x_{t-1}$ is a function of $x_{t-1}$:
\[
\Delta x_t = F(x_{t-1}).
\]
  * This is a special case of a first-order Markov process.
  * Being first order is not restrictive. Why?
* Long-run stability, speed of converge etc.~can be characterized by certain properties of $F$.

== Cobweb plot ==

% graph here


= Continuous time =
== Moving to continuous time ==
* Let time periods be $\Delta$ apart.
* How can we characterize the time series as $\Delta$ becomes smaller and smaller?
* We take the limit as $\Delta\to0$.
  * Often, we will have to rescale changes in the variable for the limit to make sense.

== Differential equations ==
* Suppose $x$ follows a difference equation
\[
x_{t+\Delta} - x_t = F(x_{t},\Delta).
\]
* Note that $F$ may depend on $\Delta$.
  * It is unreasonable to assume that the equation of motion is the same for a day as for a year.
* Let's look at the ''rate'' of change in $x$:
\[
\frac{x_{t+\Delta} - x_t}{\Delta} = \frac{F(x_{t},\Delta)}{\Delta}.
\]

== Infinitesimal changes ==
* Now let $\Delta\to0$:
\[
\lim_{\Delta\to0}\frac{x_{t+\Delta} - x_t}{\Delta } \equiv \frac{dx(t)}{dt} \equiv \dot x(t)
\]
\[
\dot x(t) = \lim_{\Delta \to0}\frac{F(x_{t},\Delta )}{\Delta } \equiv f(x_t).
\]
* Note that for $f(x_t)$ to exist, $F(x_{t},\Delta )$ has to be $O(\Delta )$.
  * [[Big-O, small-o|Detour: $O,o$ notation]].
...
* Dynamics is described by the above ordinary differential equation.
* Often, we cannot solve for $x(t)$ in closed form.
* We can still characterize the steady state, its stability, speed of convergence by the properties of $f$.

== Steady state ==
* The steady state of this system is $x^*$ such that
\[
f(x^*) = 0.
\]

== Stability ==
* The local stability of the steady state depends on the derivative (''gradient'') of $f$.
* (See Katrin's math course for details.)

== Example 1: The Solow model ==
* The law of motion for capital in the Solow model:
\[
\dot k = sf(k)-\delta k.
\]
* The steady-state capital is implicitly given by
\[
sf(k^*) = \delta k^*.
\]
* The steady state is stable if $f$ is concave.

== Phase diagram ==

== Example 2: The Ramsey model ==
* The law of motion for capital and consumption in the Ramsey model (we will derive it later):
\begin{align*}
\dot k &= f(k)-\delta k-c\\
\dot c &= \frac{f'(k)- \delta- \rho}{\theta}c
\end{align*}

== Phase diagram ==







= Appendix =
== Big-O, small-o ==
=== Big-$O$ ===
A function $f(x)$ is $O(g(x))$ for a known function $g(x)$ if
\[
\lim_{x\to0}\frac{f(x)}{g(x)}<\infty
\]
=== Small-$o$ ===
A function $f(x)$ is $o(g(x))$ for a known function $g(x)$ if
\[
\lim_{x\to0}\frac{f(x)}{g(x)}=0
\]

== Examples ==
* $f(x)=x^2$ is both $O(x)$ and $o(x)$. It is also $O(x^2)$.
* $f(x)=x^2+2x$ is $O(x)$ but not $o(x)$.
* $f(x)=x^2+2x+4$ is not $O(x)$.
